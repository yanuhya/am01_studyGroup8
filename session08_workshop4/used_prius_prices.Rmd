---
title: "Worked Example: Prius Prices"
author: "Your name goes here"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: flatly
    highlight: zenburn
    toc: yes
    toc_float: yes
---



```{r huxtable-stuff, include=FALSE}
options("huxtable.knit_print_df" = FALSE)
library(here)
library(moderndive)
library(tidyverse)
library(infer)
library(mosaic)
library(huxtable)
library(kableExtra)
library(skimr)
library(ggfortify)
library(car)
```



# What drives used Prius prices?

A recent article in the UK claimed that [your Uber cab is most likely to be a Toyota Prius](https://www.motoringresearch.com/car-news/your-uber-cab-is-most-likely-to-be-a-toyota-prius-and-why-thats-a-good-thing/).

In this workshop, you will use a data file of prices for used Toyota Prius (collected in June 2018) to describe and analyse the dataset, and use your skills in 'telling a story with data'.

Your task is to carry out analyses of the relationships between price, mileage, colour, and model year for a selected type of car.

You are expected to use this template to create a report with tables, charts, and analysis that will help us understand what drives the price of a used Prius. For instance, you may find the following questions useful in your analysis:

- How much do cars cost?
-	How much do car prices vary my engine size, year, etc?
-	How are car prices associated with mileage? Age? Colour? Location?
-	How quickly do new cars depreciate?
-	How much does it cost to drive a car one extra mile?


# Loading the data set, summary statistics


You can load the data, glimpse its structure, and get a quick feel of summary statistics
```{r load-prius-data, message=FALSE, warning=FALSE}

prius <- read_csv(here::here("data","toyota_prius_jun18.csv"))

skim(prius)
```

The data frame contains prices of used Toyota Prius in the UK that were gathered in June 2018. 

`town`, `region` and `colour` are categorical variables, whereas `miles` and `price` are numerical variables.

`year` and `engine` are treated as quantitative variables, but in reality are categorical variables.



```{r summarystats1}
prius <- prius %>% 
  mutate(
    engine = factor(engine),# turn it to a factor
    car_age = 2018- year 
  )

favstats(price ~ year, data=prius)

favstats(price ~ engine, data=prius)

favstats(price ~ colour, data=prius)


```


# 'Manual' calculations of confidence intervals for 2010 and 2011 mean prices

Before we go on, note that the average value for a 2010 model is 6354, whereas a 2011 model goes on average for 8588. Can you construct two 95% Confidence Intervals for the mean price of 2010 and 2011 used Prius?

```{r}
# Calculate critical values for the t-distribution for a cumulative of 0.975, i.e., leaving 2.5% on one side

#For 2010 cars, since we have n=28 observations, we have 28-1 = 27 degrees of freedom
qt(0.975, 27)

#For 2011 cars, since we have n=13 observations, we have 13-1 = 12 degrees of freedom
qt(0.975, 12)

```
Given the critical t-values, write down the equations to get 95% confidence intervals for the average price of a 2010 and a 2011 Prius.

> WRITE YOUR ANSWER AFTER THIS BLOCKQUOTR


I do not want you to give an R formulas; just type what you think is the correct answer.
(Your formulas should go about here)


# Relationship between price and miles



```{r, price_miles_scatter}
# plot scatter plot and add the best straight line
ggplot(prius, aes(x=miles, y = price))+
  geom_point()+
  theme_bw()+
  geom_smooth(method="lm", se=FALSE)+
  NULL
```






```{r, lm_models}
# run linear regression, lm model
model1 <- lm(price ~ miles, data = prius)

# get regression output table
model1 %>% 
  get_regression_table()

# get R Square
model1 %>% 
  get_regression_summaries()

# plot residuals
autoplot(model1) +
  theme_bw()

#add engine size, as a factor
model2 <- lm(price ~ miles + engine, data = prius)

# get regression output table
model2 %>% 
  get_regression_table()

# get R Square
model2 %>% 
  get_regression_summaries()

# plot residuals
autoplot(model2) + 
  theme_bw()



#add car age
model3 <- lm(price ~ miles + engine + car_age, data = prius)

# get regression output table
model3 %>% 
  get_regression_table()

# get R Square
model3 %>% 
  get_regression_summaries()

# plot residuals
autoplot(model3) + theme_bw()

# ________________________________________________________
#add colour and region
model4 <- lm(price ~ miles + engine + car_age + colour + region, data = prius)

# get regression output table
model4 %>% 
  get_regression_table()

# get R Square
model4 %>% 
  get_regression_summaries()

# plot residuals
autoplot(model4, which = 1:3) + theme_bw()

# no colours are significant. In addition, most regions are not significant, but let us just 
# mutate a new dummy variable "london" to see if london only has an impact

prius <- prius %>% 
  mutate(london = region=="London")

#add colour and dummy for london
model5 <- lm(price ~ miles + engine + car_age+ london, data = prius)

# get regression output table
model5 %>% 
  get_regression_table()

# get R Square
model5 %>% 
  get_regression_summaries()

# plot residuals
autoplot(model5, which = 1:3) + theme_bw()

```


# What engine size depreciates faster

Remember the simple scatterplot? what if we coloured the points by `engine`?
We will get a scatter plot of how mileage changes price, accoridng to the two engine sizes we have, 1497 and 1798.

```{r, scatter_by_engine}

ggplot(prius, aes(x=miles, y = price, colour= engine))+
  geom_point()+
  theme_bw()+
  geom_smooth(method="lm", se=FALSE)
```

This means that the effect of mileage depends on engine size. If we have two explanatory variables, and the value of one (effect of mileage) depends on the other (engine size), then besides the two variables, we also introduce an interaction variable, which is the product of the two.

```{r, interaction}
# ________________________________________________________

model6 <- lm(price ~ miles+ engine + car_age + london + miles*engine, data = prius)

# get regression output table
model6 %>% 
  get_regression_table()

# get R Square
model6 %>% 
  get_regression_summaries()

# plot residuals
autoplot(model6) + 
  theme_bw()


```


All models show a serious non-linearity in the residuals, so we have to transform `miles`. For now, let us create a summary table for all models

```{r, all_lm_models}

# produce summary table comparing models using huxtable::huxreg()
huxreg(model1, model2, model3, model6,
       statistics = c('#observations' = 'nobs', 
                      'R squared' = 'r.squared', 
                      'Adj. R Squared' = 'adj.r.squared', 
                      'Residual SE' = 'sigma'), 
       number_format = "%.2f", 
       stars = NULL
) %>% 
  set_caption('Comparison of models')

```


# Regression for prediction

Without transforming variables, the last model seems to be the best model-- everything is significant and has the highest R^2. 


```{r, predict}
# The residual standard error is 1469 pounds. So to construct any prediction interval
# we would need to +- roughly 2*1469 = 2938 pounds


mosaic::msummary(model6)



# we need to plug in the values to our equation. Consider a car that is 
# 8 years old, has 45K miles, in London. First, let us look at the impact of engine size
imaginary_car1 <- data_frame(car_age = 8,
                             miles = 45000,
                             london=TRUE,
                             engine = factor(c(1497,1798))
)

predict.lm(model6, imaginary_car1, interval = "prediction")


# A 45K miles, 1798cc car, in London with ages between 1-10 years.
imaginary_car2 <- data_frame(miles = 45000,
                            engine = factor(1798),
                            london=TRUE,
                            car_age = 1:10
)

predict.lm(model6, imaginary_car2, interval = "prediction")



```